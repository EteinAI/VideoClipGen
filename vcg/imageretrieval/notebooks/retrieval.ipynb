{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44707fa-4bd4-48b8-824c-ffd169534c5d",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69c7ea",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# local path to image library\n",
    "library_path = ''\n",
    "\n",
    "# local image folder that stores downloaded images\n",
    "image_folder = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f52eb5-cacb-41cd-89c0-4ee5d7fcd707",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Config module search path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0ddcb",
   "metadata": {
    "tags": [
     "path"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get my_package directory path from Notebook\n",
    "parent_dir = str(Path().resolve().parents[1])\n",
    "\n",
    "# Add to sys.path\n",
    "if parent_dir not in sys.path:\n",
    "  sys.path.insert(0, parent_dir)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147b9391-1580-4c03-ad2a-6f7bc516e7ec",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1d52c-9d0d-4471-8d1b-c60f6bb4b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# to support chinese\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Heiti TC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad4445",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build image index with CLIP ViT-L/14\n",
    "\n",
    "model: https://huggingface.co/openai/clip-vit-large-patch14\n",
    "\n",
    "Image index is constructed with four columns:\n",
    "- Category: Name of the category to which the images belong\n",
    "- Filepath: image file path relative to the `index.pq` file, which **_MUST BE_** placed under the root folder\n",
    "- Cluster: cluster id if index is built with knn, the smaller the cluster id, the larger the number of images in the cluster.\n",
    "  - Knn is performed within a single category.\n",
    "- Embedding: image embedding encoded with ViT-L/14\n",
    "\n",
    "Image index is built with Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db65570-4524-4a79-81dd-c7091a0b1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload ViT model\n",
    "\n",
    "from imageretrieval.retrieval import ImageEmbeddings\n",
    "\n",
    "image_encoder = ImageEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d63042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(root_path, persist=False):\n",
    "  df = index_images(root_path)\n",
    "  if persist:\n",
    "    d = df.with_columns(df['filepath'].apply(lambda x: os.path.relpath(x, root_path)))\n",
    "    d.write_parquet(os.path.join(root_path, 'index.pq'))\n",
    "  return df\n",
    "\n",
    "\n",
    "def load_index(root_path):\n",
    "  df = pl.read_parquet(os.path.join(root_path, 'index.pq'))\n",
    "  df = df.with_columns(df['filepath'].apply(lambda x: os.path.join(root_path, x)))\n",
    "  return df\n",
    "\n",
    "\n",
    "def clustering(embeddings, k=2) -> list[list[int]]:\n",
    "  from sklearn.cluster import KMeans\n",
    "  from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "  # Calculate cosine similarity between embeddings\n",
    "  similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "  # Perform K-Means clustering on the similarity matrix\n",
    "  kmeans = KMeans(\n",
    "    n_clusters=k,\n",
    "    random_state=0,\n",
    "    n_init=10\n",
    "  ).fit(similarity_matrix)\n",
    "\n",
    "  # Group the images based on their cluster assignments\n",
    "  groups: list[list[int]] = [[] for _ in range(k)]\n",
    "  for i, idx in enumerate(kmeans.labels_):\n",
    "    groups[idx].append(i)\n",
    "\n",
    "  return sorted(groups, key=lambda x: len(x), reverse=True)\n",
    "\n",
    "\n",
    "def index_images(folder_path, seen=[], df=None, recursive=True, k=1):\n",
    "  categories = []\n",
    "  filepath = []\n",
    "  cluster = []\n",
    "  embedding = []\n",
    "\n",
    "  # Only treat leaf directories as catetories\n",
    "  leaf_dirs = [p for p in Path(folder_path).rglob('**') if not any(s != p for s in p.glob('**'))]\n",
    "  for path in leaf_dirs:\n",
    "    print(f'Processing {path}...')\n",
    "\n",
    "    category = os.path.relpath(path, folder_path).replace('/', '.')\n",
    "    if category == '.':\n",
    "      category = os.path.basename(folder_path)\n",
    "    if category in seen:\n",
    "      base = category\n",
    "      suf = 1\n",
    "      while True:\n",
    "        candidate = '-'.join([base, str(suf)])\n",
    "        if candidate not in seen:\n",
    "          category = candidate\n",
    "          break\n",
    "        suf += 1\n",
    "    seen.append(category)\n",
    "\n",
    "    image_files = [\n",
    "      *path.glob('**/*.png'),\n",
    "      *path.glob('**/*.jpg'),\n",
    "      *path.glob('**/*.jpeg'),\n",
    "    ]\n",
    "    embeddings = image_encoder.encode(image_files)\n",
    "    print('Shape:', embeddings.shape)\n",
    "\n",
    "    groups = clustering(embeddings, k) if k > 1 else [range(len(embeddings))]\n",
    "    for idx, group in enumerate(groups):\n",
    "      for i in group:\n",
    "        categories.append(category)\n",
    "        filepath.append(str(image_files[i]))\n",
    "        cluster.append(idx)\n",
    "        embedding.append(embeddings[i])\n",
    "\n",
    "  frame = pl.DataFrame({\n",
    "    'category': categories,\n",
    "    'filepath': filepath,\n",
    "    'cluster': cluster,\n",
    "    'embedding': embedding,\n",
    "  })\n",
    "\n",
    "  return frame if df is None else df.extend(frame)\n",
    "\n",
    "\n",
    "def image_plot(title, similarities, images, count=8, w=50):\n",
    "  from matplotlib import pyplot as plt\n",
    "  from textwrap import wrap\n",
    "  from PIL import Image\n",
    "\n",
    "  col = 4\n",
    "  row = (count + col - 1) // col\n",
    "  fig = plt.figure(figsize=(16, row * 4), dpi=300)\n",
    "  for i in range(min(count, len(images))):\n",
    "    plt.subplot(row, col, i + 1)\n",
    "    plt.imshow(Image.open(images[i]).convert('RGB'))\n",
    "    plt.title(f'{os.path.basename(images[i])}\\n{similarities[i]}', size=12)\n",
    "  fig.suptitle('\\n'.join(wrap(title, w)), size=16)\n",
    "\n",
    "\n",
    "def retrieval(sentences: list[str], df):\n",
    "  \"\"\"\n",
    "  Text-based image retrieval\n",
    "  \"\"\"\n",
    "\n",
    "  text_embeddings = text_encoder.encode(sentences)\n",
    "\n",
    "  def similarity(expr=True, top=8, visualize=True):\n",
    "    sub = df.filter(expr)\n",
    "    image_embeddings = np.array(list(sub['embedding']))\n",
    "\n",
    "    scores = np.dot(text_embeddings, image_embeddings.T)\n",
    "    indices = np.argsort(scores, axis=1)[:, ::-1]\n",
    "#     print(f'Scores: {scores}')\n",
    "#     print(f'Indices: {indices}')\n",
    "\n",
    "    seen = []\n",
    "    selected = []\n",
    "    files = list(sub['filepath'])\n",
    "    categories = list(sub['category'])\n",
    "    for idx, text in enumerate(sentences):\n",
    "      for i in indices[idx]:\n",
    "        if i not in seen:\n",
    "          selected.append((categories[i], files[i]))\n",
    "          break\n",
    "      if visualize:\n",
    "        images = [files[i] for i in indices[idx]]\n",
    "        similarities = [scores[idx][i] for i in indices[idx]]\n",
    "        image_plot(text, similarities, images, count=top)\n",
    "    return selected\n",
    "\n",
    "  return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6876c-2e80-451a-bdaf-74b188c81653",
   "metadata": {},
   "source": [
    "## Load image index from library\n",
    "\n",
    "`index.pq` **_MUST_** exist in the `library_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41293963-e7c9-43b1-9d3f-4151b81c2307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(library_path):\n",
    "  raise RuntimeError(f'Path not found: {library_path}')\n",
    "\n",
    "df = load_index(library_path)\n",
    "\n",
    "print(f'Root directory: {library_path}')\n",
    "print(f'Total images: {df.height}')\n",
    "print(f'Categories: {list(df[\"category\"].unique())}')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4948bb4a-35a8-42fd-b6cd-d62586c53168",
   "metadata": {},
   "source": [
    "## Add image from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313c8be-933d-4b2c-b5b0-6bf314f875b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(image_folder):\n",
    "  raise RuntimeError(f'Path not found: {image_folder}')\n",
    "\n",
    "seen = list(df['category'].unique()) if df is not None else []\n",
    "newdf = index_images(image_folder, seen=seen, k=2)\n",
    "print(f'Total images: {newdf.height}')\n",
    "print(f'Categories: {list(newdf[\"category\"].unique())}')\n",
    "print(newdf)\n",
    "\n",
    "df = newdf if df is None else df.extend(newdf)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e28b7-e3ae-4de2-b483-13a063d2597a",
   "metadata": {},
   "source": [
    "# Text-based image retrieval\n",
    "\n",
    "https://huggingface.co/M-CLIP/XLM-Roberta-Large-Vit-L-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889e159-b052-4b3d-81a3-b82b92ae07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preload multilingual model\n",
    "\n",
    "from imageretrieval.retrieval import TextEmbeddings\n",
    "\n",
    "text_encoder = TextEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0be6b6-b2db-4d58-81af-98612e1a7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "  '这145平米的样板间采用10多种色彩，创造了和谐、高级的空间',\n",
    "  '客餐厅采用无吊顶设计，左右清晰分区',\n",
    "  '墙面、顶面和门框采用黑色金属线条，营造简约现代感',\n",
    "  '餐椅和抱枕的脏橘色贯穿客餐厅，避免了视觉上的割裂感',\n",
    "  '选择雅琪诺悦动风华系列的窗帘，营造出温馨的氛围',\n",
    "  '主卧和次卧都采用了不同的装饰元素，呈现出不同的风格，相应地丰富了整个空间'\n",
    "]\n",
    "similarity = retrieval(sentences, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bc781-b8a8-4dc7-a45b-309358a74d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity(pl.col('cluster')==0, top=8, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfda514-cc71-4ba0-8f61-0fd6b8a71452",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876073e3-62db-45ab-be3f-1a2fc1f7e04e",
   "metadata": {},
   "source": [
    "## Build and save image index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dc8a6-ad92-40e5-9b54-f7899d1144a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in your local path\n",
    "root_path = ''\n",
    "\n",
    "if not os.path.exists(root_path):\n",
    "  raise RuntimeError(f'Path not found: {root_path}')\n",
    "\n",
    "build_index(root_path, persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53ab9d-49ab-4087-8a88-f6622929a0c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## List all available fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8f6fc4-33de-45a0-bdb4-89972538039b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontManager\n",
    "fm = FontManager()\n",
    "mat_fonts = set(f.name for f in fm.ttflist)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(mat_fonts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec3f3d-147c-48f5-a909-52a30f506033",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pl.DataFrame({\n",
    "  'a': ['str1', 'str2'],\n",
    "  'b': ['str3', 'str4'],\n",
    "})\n",
    "d2 = d1.with_columns(d1['a'].apply(lambda x: os.path.join('aa', x)))\n",
    "d1.extend(d2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
